from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from transformers import AutoTokenizer, AutoModel
import torch
import chromadb
from chromadb.config import Settings

load_dotenv()

GEMINI_KEY = os.getenv("GEMINI_API_KEY")
GEMINI_API_URL = os.getenv("GEMINI_API_URL")

app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
class PaperRequest(BaseModel):
    text: str
    top_n: int = 5  # default number of journals
model_name = "allenai/scibert_scivocab_uncased"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModel.from_pretrained(model_name)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
model.eval()
client = chromadb.Client(Settings(
    chroma_db_impl="duckdb+parquet",
    persist_directory="./chroma_db"
))
collection = client.get_or_create_collection(name="journals")
def embed_text(text: str):
    encoded_input = tokenizer(
        text,
        padding=True,
        truncation=True,
        return_tensors="pt"
    )
    input_ids = encoded_input["input_ids"].to(device)
    attention_mask = encoded_input["attention_mask"].to(device)
    with torch.no_grad():
        outputs = model(input_ids=input_ids, attention_mask=attention_mask)
        last_hidden_state = outputs.last_hidden_state
    input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()
    sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, dim=1)
    sum_mask = torch.clamp(input_mask_expanded.sum(dim=1), min=1e-9)
    embedding = sum_embeddings / sum_mask
    return embedding.cpu().numpy()
def query_chroma_journals(collection, input_text: str, top_n: int):
    input_embedding = embed_text(input_text)
    results = collection.query(
        query_embeddings=[input_embedding],
        n_results=top_n)
    journals_list = []
    for i in range(len(results['ids'][0])):
        journal_info = {
            "name": results['metadatas'][0][i].get("name", ""),
            "description": results['documents'][0][i],
            "score": results['distances'][0][i]
        }
        journals_list.append(journal_info)
    return journals_list
@app.post("/search_journals")
def search_journals(request: PaperRequest):
    if not request.text:
        raise HTTPException(status_code=400, detail="Input text is required")
    
    try:
        top_journals = query_chroma_journals(collection, request.text, request.top_n)
        return {"results": top_journals}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
    
class GeminiRequest(BaseModel):
    prompt: str

class GeminiResponse(BaseModel):
    generated_text: str
    

# api key
@app.post("/generate", response_model=GeminiResponse)
async def generate_text_from_gemini(request_body: GeminiRequest):
    """
    Accepts a prompt and returns text generated by the Gemini model.
    """
    if not GEMINI_KEY:
        raise HTTPException(status_code=500, detail="GEMINI_API_KEY is not set.")

    # 1. Format the request payload for the Gemini API
    # The structure follows the Gemini API documentation.
    payload = {
        "contents": [
            {
                "parts": [
                    {
                        "text": request_body.prompt
                    }
                ]
            }
        ]
    }

    # 2. Make the asynchronous API call to Gemini
    try:
        # We use an async client to not block the FastAPI server
        async with httpx.AsyncClient() as client:
            response = await client.post(
                GEMINI_API_URL,
                json=payload,
                headers={"Content-Type": "application/json"},
                timeout=30.0 # Set a timeout for the request
            )
            # Raise an exception if the request was unsuccessful
            response.raise_for_status()
            
            # 3. Process the response from Gemini
            gemini_data = response.json()
            
            # Extract the generated text from the nested JSON structure.
            # It's good practice to add error handling for different response structures.
            generated_text = gemini_data.get("candidates", [{}])[0].get("content", {}).get("parts", [{}])[0].get("text", "")

            if not generated_text:
                raise HTTPException(status_code=500, detail="Could not extract generated text from Gemini response.")

            # 4. Return the formatted response
            return GeminiResponse(generated_text=generated_text)

    except httpx.HTTPStatusError as e:
        # Handle specific HTTP errors from the Gemini API
        raise HTTPException(status_code=e.response.status_code, detail=f"Gemini API error: {e.response.text}")
    except Exception as e:
        # Handle other potential errors (e.g., network issues)
        raise HTTPException(status_code=500, detail=f"An error occurred: {str(e)}")
